{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "54914638",
   "metadata": {},
   "source": [
    "# Vista Enhancer\n",
    "    \n",
    "    The VISTA Enhancer Browser is a central resource for experimentally validated human and mouse noncoding fragments with gene enhancer activity as assessed in transgenic mice. Most of these noncoding elements were selected for testing based on their extreme conservation in other vertebrates or epigenomic evidence (ChIP-Seq) of putative enhancer marks. The results of this in vivo enhancer screen are provided through this publicly available website.\n",
    "\n",
    "## URL : https://enhancer.lbl.gov/ \n",
    "\n",
    "### Data download - 06/12/2023\n",
    "\n",
    "#### Query selection\n",
    "\n",
    "Browse the database in the 'Advanced search' https://enhancer.lbl.gov/cgi-bin/imagedb3.pl?form=ext_search&show=1\n",
    "\n",
    "1) Expression pattern: All\n",
    "2) Only 'Positive' enhancers\n",
    "3) Only 'Humans'\n",
    "\n",
    "Query results in 1002 elements with a data download link\n",
    "\n",
    "https://enhancer.lbl.gov/cgi-bin/imagedb3.pl?action=search;page=1;search.org=Human;search.status=Positives;search.gene=;form=ext_search;search.result=yes;page_size=100;show=1;search.sequence=1\n",
    "\n",
    "Output is a preformatted text provided in HTML as a 'pre' element\n",
    "\n",
    "\n",
    "\n",
    "## Citing the Enhancer Browser\n",
    "\n",
    "The following publication should be referenced for any analysis in which data from the VISTA Enhancer Browser was used:\n",
    "\n",
    "Visel A, Minovitsky S, Dubchak I, Pennacchio LA (2007). VISTA Enhancer Browser-a database of tissue-specific human enhancers. Nucleic Acids Res 35:D88-92\n",
    "\n",
    "When referring to specific datasets within the Enhancer Browser, please report the respective dataset ID, e.g. hs112 or mm23."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "042e83ef",
   "metadata": {},
   "source": [
    "## Data Extraction and Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "21860a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "\n",
    "import requests\n",
    "import re\n",
    "import subprocess\n",
    "import os\n",
    "import glob\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "b5c92b3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get the strand information using Samtools faidx\n",
    "# wget https://hgdownload.soe.ucsc.edu/goldenPath/hg19/bigZips/hg19.fa.gz\n",
    "def get_strand(sequence):\n",
    "    fa = \"hg19.fa\"\n",
    "    output = subprocess.check_output([\"samtools\", \"faidx\", fa, sequence, \"--mark-strand\", \"sign\"]).decode(\"utf-8\")\n",
    "    lines = output.split('\\n')\n",
    "    strand = lines[0].replace('>', '')\n",
    "    value = re.search(r'\\((.*?)\\)', strand).group(1)\n",
    "    ref_sequence = ''.join(lines[1:])\n",
    "    return value, ref_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "b7fa1ac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get gene information from experiment page\n",
    "def get_experiment_info(experiment_id):\n",
    "    # Construct the URL for the experiment ID\n",
    "    url = f\"https://enhancer.lbl.gov/cgi-bin/imagedb3.pl?form=presentation&show=1&experiment_id={experiment_id}&organism_id=1\"\n",
    "\n",
    "    # Send a GET request to the URL\n",
    "    response = requests.get(url)\n",
    "    html_content = response.text\n",
    "    \n",
    "    # Parse the HTML content with BeautifulSoup\n",
    "    soup = BeautifulSoup(html_content, 'html.parser')\n",
    "    \n",
    "    # Extract the position\n",
    "    position_element = soup.find('b', text='Position:')\n",
    "    if position_element:\n",
    "        position = position_element.find_next_sibling(text=True).strip()\n",
    "        position = position.replace(' (', '').replace(',', '')\n",
    "    else:\n",
    "        position = None\n",
    "    \n",
    "    # Extract the flanking genes\n",
    "    flanking_genes_element = soup.find('b', text='Flanking genes:')\n",
    "    if flanking_genes_element:\n",
    "        flanking_genes = flanking_genes_element.find_next_siblings('a')\n",
    "        flanking_genes = [gene.text.strip() for gene in flanking_genes]\n",
    "        flanking_genes = '-'.join(flanking_genes)\n",
    "    else:\n",
    "        flanking_genes = None\n",
    "    \n",
    "    # Return the extracted information\n",
    "    return position, flanking_genes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98bef320",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Send a GET request to the webpage\n",
    "url = 'https://enhancer.lbl.gov/cgi-bin/imagedb3.pl?page=1;show=1;form=ext_search;order=;search.gene=;search.result=yes;search.status=Positives;action=search;search.org=Human;page_size=100;search.sequence=1'\n",
    "response = requests.get(url)\n",
    "text_content = response.text\n",
    "\n",
    "# Find all entries starting with \">Human\"\n",
    "entries = re.findall(r'>Human.*?(?=^>Human|\\Z)', text_content, re.MULTILINE | re.DOTALL)\n",
    "\n",
    "# Remove '</pre' from the last entry\n",
    "last_entry = entries[-1]\n",
    "entries[-1] = re.sub('</pre', '', last_entry)\n",
    "\n",
    "# Define the output file name\n",
    "output_file = 'VISTA_Human_enhancers_sequences.bed'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "a19eca59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the output file and write the header\n",
    "with open(output_file, 'w') as file:\n",
    "    # Write the header\n",
    "    headers = ['#chrom', 'chromStart', 'chromEnd', 'name', 'score', 'strand', 'annotation', 'sequence', 'expressionPattern', 'Flanking_genes']\n",
    "    file.write('\\t'.join(headers) + '\\n')\n",
    "\n",
    "    # Create a set to store the unique expression patterns\n",
    "    tissue_categories = set()\n",
    "\n",
    "    # Process and write each entry to the output file\n",
    "    for entry in entries:\n",
    "        # Remove '>' character and newlines, replace '|' with tab '\\t' (removing surrounding spaces)\n",
    "        entry = re.sub(r'[>\\n]|(\\s*\\|\\s*)', lambda m: '\\t' if m.group(1) else '', entry)\n",
    "        # Split the columns\n",
    "        columns = entry.split('\\t')\n",
    "        # Rearrange the last column (ear[6/6]CTCCCCTgg)\n",
    "        last_column_parts = re.split(r'(\\])', columns[-1])\n",
    "        # Combine the last_column_parts with the rest of the columns\n",
    "        combined_columns = columns[0:2] + ['_'.join(columns[2].split())] + columns[3:-1] + [last_column_parts[0] + last_column_parts[1], last_column_parts[2]]\n",
    "        # Join the combined columns with '\\t' separator\n",
    "        combined_entry = '\\t'.join(combined_columns)\n",
    "        # Extract entries between 4th and last column\n",
    "        column_4_to_last = combined_entry.split('\\t')[4:-1]\n",
    "        # Combine entries between 4th and last column\n",
    "        joined_column_4_to_last = ';'.join(column_4_to_last)\n",
    "        # Split the joined_column_4_to_last by ';'\n",
    "        split_last_column = joined_column_4_to_last.split(';')\n",
    "        # Get strand and reference sequence\n",
    "        strand, ref_sequence = get_strand(combined_entry.split('\\t')[1])\n",
    "        # Split sequence identifier into chromosome, start and end\n",
    "        chromosome, position = combined_entry.split('\\t')[1].split(':')\n",
    "        start_position, end_position = position.split('-')\n",
    "\n",
    "        # Iterate over expression patterns\n",
    "        for item in split_last_column:\n",
    "            # Parsing the expression patterns ('trigeminal V (ganglion, cranial)[3/5]')\n",
    "            expression_pattern = item.strip().split('[')[0].strip().replace(' ', '_').replace(',', '').capitalize().replace('(', '').replace(')', '')\n",
    "            # Extract the score from within the square brackets and convert to decimal\n",
    "            score_parts = re.search(r'\\[(.*?)\\]', item).group(1).split('/')\n",
    "            score_decimal = int(score_parts[0]) / int(score_parts[1])\n",
    "            # Format the score as a decimal with two decimal places\n",
    "            score_formatted = \"{:.2f}\".format(score_decimal)\n",
    "            # Add the expression pattern to the set\n",
    "            tissue_categories.add(expression_pattern)\n",
    "            # Get experiment ID\n",
    "            element_id = combined_columns[2].split('_')[1]\n",
    "            # Replace the prefix 'element_' with 'hg'\n",
    "            element_name = combined_columns[2].replace('element_', 'hs')\n",
    "            # Get Flanking genes infomation from the experiment page\n",
    "            position, gene = get_experiment_info(element_id)\n",
    "            # Handle None value for gene\n",
    "            flanking_gene = gene if gene else ''\n",
    "            # Write the entry with rearranged columns\n",
    "            columns = [chromosome, start_position, end_position, element_name, score_formatted, strand, combined_columns[3], combined_columns[-1], item, ref_sequence, position]\n",
    "\n",
    "            # Check if the enhancer_sequence match with reference_sequence\n",
    "            if len(columns) >= 10:\n",
    "                # Get column 8 and column 10 (ignoring capitalization)\n",
    "                enh_seq = columns[7].strip()\n",
    "                ref_seq = columns[9].strip()\n",
    "\n",
    "                position1 = combined_entry.split('\\t')[1]\n",
    "                position2 = columns[10]\n",
    "\n",
    "                if position1 == position2:\n",
    "                    flanking_gene = gene\n",
    "                else:\n",
    "                   flanking_gene = \"None\"\n",
    "\n",
    "                # Compare column 7 and column 9 (ignoring capitalization)\n",
    "                if enh_seq.lower() == ref_seq.lower() and position1 == position2:\n",
    "                    strand = \"+\"\n",
    "                    rearranged_columns = [chromosome, start_position, end_position, element_name, score_formatted, strand, combined_columns[3], combined_columns[-1], item, flanking_gene]\n",
    "                else:\n",
    "                    strand = '-'\n",
    "                    rearranged_columns = [chromosome, start_position, end_position, element_name, score_formatted, strand, combined_columns[3], combined_columns[-1], item, flanking_gene]\n",
    "\n",
    "\n",
    "            # Write the entry with rearranged columns\n",
    "            file.write('\\t'.join(rearranged_columns) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "6da19804",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the directory to store the expression pattern files\n",
    "expression_pattern_files_directory = 'Tissue_specific_files'\n",
    "os.makedirs(expression_pattern_files_directory, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "8ffae017",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the entries based on tissue category\n",
    "for tissue in tissue_categories:\n",
    "    tissue_filename = f'{expression_pattern_files_directory}/{tissue}.{output_file}'\n",
    "    with open(output_file, 'r') as input_file, open(tissue_filename, 'w') as tissue_file:\n",
    "        # Write the header to the individual tissue files\n",
    "        tissue_file.write('\\t'.join(headers) + '\\n')\n",
    "        for line in input_file:\n",
    "            # Compare the pattern to the expressionPattern column\n",
    "            expression_pattern = line.split('\\t')[-2].strip().split('[')[0].strip().replace(' ', '_').replace(',','').capitalize().replace('(','').replace(')','')\n",
    "            # pattern_match = columns.strip().split('[')[0].strip().replace(' ', '_')\n",
    "            if expression_pattern == tissue:\n",
    "                tissue_file.write(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "dafcc7a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort each tissue specific files individually\n",
    "file_pattern = f\"{expression_pattern_files_directory}/*.bed\"\n",
    "file_list = glob.glob(file_pattern)\n",
    "\n",
    "for file_path in file_list:\n",
    "    #print (file_path)\n",
    "    sort_command = f\"LC_ALL=C sort -k1,1 -k2,2n -k3,3n {file_path} -o {file_path}\"\n",
    "    subprocess.run(sort_command, shell=True)\n",
    "\n",
    "# Compress and index the sorted files using bgzip and tabix\n",
    "for file_path in file_list:\n",
    "    bgzip_command = f\"bgzip -f {file_path}\"\n",
    "    subprocess.run(bgzip_command, shell=True)\n",
    "\n",
    "    tabix_command = f\"tabix -f -p bed {file_path}.gz\"\n",
    "    subprocess.run(tabix_command, shell=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "40edcbb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output has been written to 'VISTA_Human_enhancers_sequences.bed' file.\n",
      "Tissue specific files have been created in the 'Tissue_specific_files' directory.\n"
     ]
    }
   ],
   "source": [
    "print(\"Output has been written to 'VISTA_Human_enhancers_sequences.bed' file.\")\n",
    "print(f\"Tissue specific files have been created in the '{expression_pattern_files_directory}' directory.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3633123",
   "metadata": {},
   "source": [
    "## Processed Output\n",
    "Ouput is a tissue specific enhancer sequences with expression pattern in BED like format. (BED6+4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "8dd00f91",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#chrom\tchromStart\tchromEnd\tname\tscore\tstrand\tannotation\tsequence\texpressionPattern\tFlanking_genes\n",
      "chr16\t86430087\t86430726\ths1\t1.00\t+\tpositive\tAACTGAAGGGACCCCGTTAGCATAtaaacaaaaggtggggggtagccccgagcctcttctctgacagccagtggcggcagtgatgaatttgtgaagttatctaattttccactgttttaattagagacttgggctctgaggcctcgcagctggcttctttgtgctgtattctgttgcctgacagagaaaaatgtctcctgtaacgtcagccaagctctccgccagacctgagcaagcgaaacttctgggattcataaacttgtggtttctgggtagagtggcgtttaaaccaggactcagtggggaaagggcaacatggccagctcttctccccagcgaatcctcggaaccaaggttggggtccaccatcatcgaaggggtgctgcggaaaaggcacggcccagaaagccccctgaggattgttctgggggtccttgatcctagtccatgtgaaatggagtctccttgtggcatgtaattgagcccagcttagaaaggccagtgctctgcttctccgagacagtgcctttgattgcagagtgtgtgatctgagtaatttaatttatcgctcatcttttgccaagtgatctttttacaatgctgcatttaatgactcCACAGCTGGGGTAGAGGCTCTCCT\tneural tube[12/12]\tLINC00917-FENDRR\n"
     ]
    }
   ],
   "source": [
    "# BED format\n",
    "with open(output_file, 'r') as file:\n",
    "    first_line = file.readline().strip()\n",
    "    second_line = file.readline().strip()\n",
    "\n",
    "# Print the first two lines\n",
    "print(first_line)\n",
    "print(second_line)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59980246",
   "metadata": {},
   "source": [
    "### Tissue categories:\n",
    "\n",
    "21 uniqe tissue categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "788b9a85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Blood vessels\n",
      "Branchial arch\n",
      "Cranial nerve\n",
      "Dorsal root ganglion\n",
      "Ear\n",
      "Eye\n",
      "Facial mesenchyme\n",
      "Forebrain\n",
      "Genital tubercle\n",
      "Heart\n",
      "Hindbrain rhombencephalon\n",
      "Limb\n",
      "Liver\n",
      "Melanocytes\n",
      "Midbrain mesencephalon\n",
      "Neural tube\n",
      "Nose\n",
      "Other\n",
      "Pancreas\n",
      "Somite\n",
      "Tail\n",
      "Trigeminal v ganglion cranial\n"
     ]
    }
   ],
   "source": [
    "# Tissue categories\n",
    "sorted_categories = sorted(tissue_categories, key=str.lower)  # Sort categories while ignoring case\n",
    "unique_categories = []\n",
    "for category in sorted_categories:\n",
    "    capitalized_category = category.capitalize()\n",
    "    formatted_category = capitalized_category.replace(\"_\", \" \")\n",
    "    if category.lower() not in unique_categories and formatted_category not in unique_categories:\n",
    "        unique_categories.append(formatted_category)\n",
    "\n",
    "for category in unique_categories:\n",
    "    print(category)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
