{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "54914638",
   "metadata": {},
   "source": [
    "# Vista Enhancer\n",
    "    \n",
    "    The VISTA Enhancer Browser is a central resource for experimentally validated human and mouse noncoding fragments with gene enhancer activity as assessed in transgenic mice. Most of these noncoding elements were selected for testing based on their extreme conservation in other vertebrates or epigenomic evidence (ChIP-Seq) of putative enhancer marks. The results of this in vivo enhancer screen are provided through this publicly available website.\n",
    "\n",
    "## URL : https://enhancer.lbl.gov/ \n",
    "\n",
    "### Data download - 06/12/2023\n",
    "\n",
    "#### Query selection\n",
    "\n",
    "Browse the database in the 'Advanced search' https://enhancer.lbl.gov/cgi-bin/imagedb3.pl?form=ext_search&show=1\n",
    "\n",
    "1) Expression pattern: All\n",
    "2) Only 'Positive' enhancers\n",
    "3) Only 'Humans'\n",
    "\n",
    "Query results in 1002 elements with a data download link\n",
    "\n",
    "https://enhancer.lbl.gov/cgi-bin/imagedb3.pl?action=search;page=1;search.org=Human;search.status=Positives;search.gene=;form=ext_search;search.result=yes;page_size=100;show=1;search.sequence=1\n",
    "\n",
    "Output is a preformatted text provided in HTML as a 'pre' element\n",
    "\n",
    "\n",
    "\n",
    "## Citing the Enhancer Browser\n",
    "\n",
    "The following publication should be referenced for any analysis in which data from the VISTA Enhancer Browser was used:\n",
    "\n",
    "Visel A, Minovitsky S, Dubchak I, Pennacchio LA (2007). VISTA Enhancer Browser-a database of tissue-specific human enhancers. Nucleic Acids Res 35:D88-92\n",
    "\n",
    "When referring to specific datasets within the Enhancer Browser, please report the respective dataset ID, e.g. hs112 or mm23."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "042e83ef",
   "metadata": {},
   "source": [
    "## Data Extraction and Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "21860a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "\n",
    "import requests\n",
    "import re\n",
    "import subprocess\n",
    "import os\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b5c92b3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get the strand information using Samtools faidx\n",
    "def get_strand(sequence):\n",
    "    fa = \"hg19.fa\"\n",
    "    output = subprocess.check_output([\"samtools\", \"faidx\", fa, sequence, \"--mark-strand\", \"sign\"]).decode(\"utf-8\")\n",
    "    strand = output.split('\\n')[0].replace('>', '')\n",
    "    # Extract the value inside the parentheses - chr16:78510608-78511944(+)\n",
    "    value = re.search(r'\\((.*?)\\)', strand).group(1)\n",
    "    return value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "883bb44d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Send a GET request to the webpage\n",
    "url = 'https://enhancer.lbl.gov/cgi-bin/imagedb3.pl?page=1;show=1;form=ext_search;order=;search.gene=;search.result=yes;search.status=Positives;action=search;search.org=Human;page_size=100;search.sequence=1'\n",
    "response = requests.get(url)\n",
    "text_content = response.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "af1aba4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find all entries starting with \">Human\"\n",
    "entries = re.findall(r'>Human.*?(?=^>Human|\\Z)', text_content, re.MULTILINE | re.DOTALL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "65773fa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove '</pre' from the last entry\n",
    "last_entry = entries[-1]\n",
    "entries[-1] = re.sub('</pre', '', last_entry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3459fe52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the output file name\n",
    "output_file = 'VISTA_Human_enhancers_sequences.bed'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a19eca59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the output file and write the header\n",
    "with open(output_file, 'w') as file:\n",
    "    # Write the header\n",
    "    headers = ['#chrom', 'chromStart', 'chromEnd', 'name', 'strand', 'annotation', 'sequence', 'expressionPattern']\n",
    "    file.write('\\t'.join(headers) + '\\n')\n",
    "\n",
    "    # Create a set to store the unique expression patterns\n",
    "    tissue_categories = set()\n",
    "\n",
    "    # Process and write each entry to the output file\n",
    "    for entry in entries:\n",
    "        # Remove '>' character and newlines, replace '|' with tab '\\t' (removing surrounding spaces)\n",
    "        entry = re.sub(r'[>\\n]|(\\s*\\|\\s*)', lambda m: '\\t' if m.group(1) else '', entry)\n",
    "        # Split the columns\n",
    "        columns = entry.split('\\t')\n",
    "        # Rearrange the last column (ear[6/6]CTCCCCTgg)\n",
    "        last_column_parts = re.split(r'(\\])', columns[-1])\n",
    "        # Combine the last_column_parts with the rest of the columns\n",
    "        combined_columns = columns[:-1] + [last_column_parts[0] + last_column_parts[1], last_column_parts[2]]\n",
    "        # Join the combined columns with '\\t' separator\n",
    "        combined_entry = '\\t'.join(combined_columns)\n",
    "        # Extract entries between 4th and last column\n",
    "        column_4_to_last = combined_entry.split('\\t')[4:-1]\n",
    "        # Combine entries between 4th and last column\n",
    "        joined_column_4_to_last = ';'.join(column_4_to_last)\n",
    "        # Split the joined_column_4_to_last by ';'\n",
    "        split_last_column = joined_column_4_to_last.split(';')\n",
    "        # Get strand\n",
    "        strand = get_strand(combined_entry.split('\\t')[1])\n",
    "        # Split sequence identifier into chromosome, start and end\n",
    "        chromosome, position = combined_entry.split('\\t')[1].split(':')\n",
    "        start_position, end_position = position.split('-')\n",
    "\n",
    "        # Iterate over expression patterns\n",
    "        for item in split_last_column:\n",
    "            # Parsing the expression patters ('trigeminal V (ganglion, cranial)[3/5]')\n",
    "            expression_pattern = item.strip().split('[')[0].strip().replace(' ', '_').replace(',','').capitalize().replace('(','').replace(')','')\n",
    "            rearranged_columns = [chromosome, start_position, end_position, combined_entry.split('\\t')[2], strand, combined_entry.split('\\t')[3], combined_entry.split('\\t')[-1], item]\n",
    "            # Write the entry with rearranged columns\n",
    "            file.write('\\t'.join(rearranged_columns) + '\\n')\n",
    "            # Add the expression pattern to the set\n",
    "            tissue_categories.add(expression_pattern)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6da19804",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the directory to store the expression pattern files\n",
    "expression_pattern_files_directory = 'Tissue_specific_files'\n",
    "os.makedirs(expression_pattern_files_directory, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8ffae017",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the entries based on tissue category\n",
    "for tissue in tissue_categories:\n",
    "    tissue_filename = f'{expression_pattern_files_directory}/{tissue}.{output_file}'\n",
    "    with open(output_file, 'r') as input_file, open(tissue_filename, 'w') as tissue_file:\n",
    "        # Write the header to the individual tissue files\n",
    "        tissue_file.write('\\t'.join(headers) + '\\n')\n",
    "        for line in input_file:\n",
    "            # Compare the pattern to the expressionPattern column\n",
    "            columns = line.split('\\t')[-1].strip().split('[')[0].strip().replace(' ', '_').replace(',','').capitalize().replace('(','').replace(')','')\n",
    "            # pattern_match = columns.strip().split('[')[0].strip().replace(' ', '_')\n",
    "            if columns == tissue:\n",
    "                tissue_file.write(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "990a7d7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort each tissue specific files individually\n",
    "file_pattern = f\"{expression_pattern_files_directory}/*.bed\"\n",
    "file_list = glob.glob(file_pattern)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "dafcc7a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for file_path in file_list:\n",
    "    #print (file_path)\n",
    "    sort_command = f\"LC_ALL=C sort -k1,1 -k2,2n -k3,3n {file_path} -o {file_path}\"\n",
    "    subprocess.run(sort_command, shell=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6ca5a3b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compress and index the sorted files using bgzip and tabix\n",
    "for file_path in file_list:\n",
    "    bgzip_command = f\"bgzip -f {file_path}\"\n",
    "    subprocess.run(bgzip_command, shell=True)\n",
    "\n",
    "    tabix_command = f\"tabix -f -p bed {file_path}.gz\"\n",
    "    subprocess.run(tabix_command, shell=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "40edcbb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output has been written to 'VISTA_Human_enhancers_sequences_06142023.bed' file.\n",
      "Tissue specific files have been created in the 'Tissue_specific_files' directory.\n"
     ]
    }
   ],
   "source": [
    "print(\"Output has been written to 'VISTA_Human_enhancers_sequences_06142023.bed' file.\")\n",
    "print(f\"Tissue specific files have been created in the '{expression_pattern_files_directory}' directory.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
